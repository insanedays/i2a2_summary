
          เฮ [Música] [Música] [Música] เฮ [Música] [Música] เฮ [Música] [Música] [Música] เฮ Ah, joia. Olá, pessoal. Boa noite. Estamos aqui mais uma vez reunidos para falar da do nossa do nosso curso de inteligência artificial voltada paraa criação de agentes autônomos. Lembrando sempre, né, que o o curso de agentes autônomos com redes generativas eh um oferecimento, né, é patrocinado pela Meta e MetaDatag. Sem o patrocínio e o apoio deles, nós não conseguiríamos estar aqui. Então, não custa nada lembrar disso. E hoje nós
          
          vamos tratar de um assunto interessante que é o planejamento de agentes e ferramentas. Bom, orientações gerais, né, como é de prh, vamos falar um pouquinho sobre como é que foram esses últimos dias. Então, com relação aos grupos de trabalho, nós processamos todas as alterações, foram muitas, eh, por isso que inclusive demorou um pouquinho, mas já disparei os e-mails com a formação final dos grupos, com todas as alterações que vocês nos pediram, tá? pode ser que tenha escapado alguma, porque foi muita alteração. A gente teve
          
          aí perto de de 600 e-mails que chegaram e para conseguir fazer tudo isso, eu tinha que ajustar eh às vezes um e-mail que tava errado, alguma coisa assim. Enfim, se tiver alguma divergência, não precisa se preocupar, tá? Não entra em pânico, não. Só manda um e-mail pro sac@22.acakkada atacada e me falar: "Olha, eu tô no grupo X, por favor, me coloca no grupo Y, né?" Só que assim, tenta tenta ser um pouco mais eh detalhista, porque às vezes a pessoa fala assim: "Ah, eu quero ir pro grupo sete". Hum. Às vezes o nome do grupo não
          
          é grupo sete, sabe? Tem detalhezinho. Então, quanto mais detalhista você puder sendo mensagem, melhor, porque facilita a nossa vida. Fica fácil da gente encontrar. para qual grupo você tá indo. Ah, com relação aos grupos de WhatsApp do curso, eu criei a uma comunidade, né? Eh, foi a primeira experiência que a gente teve nesse sentido. Então, eu, sinceramente, eu não sei porque que o WhatsApp tá tentando eh transferir todo mundo para todos os a grupos que estão lá dentro da comunidade. Eu achei sinceramente que ele ia manter os grupos
          
          separados e ia criar um grupo comum para todo mundo. Não foi isso que eu notei. Mas enfim, então essa história dele ficar passando gente de um grupo para outro, isso é alguma coisa que tá acontecendo automaticamente lá dentro. Eu não tenho gestão sobre isso, mas também não vejo problema nenhum, tá? Daqui a algum tempo a gente deve conseguir normalizar tudo isso. Ah, e lembrem-se que as mensagens eu vou sempre passar no grupinho lá da comunidade, que é onde tá todo mundo, que vocês não podem postar mensagem. Eu
          
          também não tenho poder para ficar configurando muita coisa, mas enfim, ali a gente consegue ter um lugar único onde vão estar todas as mensagens relacionadas ao curso, que era uma reclamação antiga de todos os alunos, né, falando: "Olha, tem muita mensagem, não sei o quê". Eu acabo me perdendo então é só ir lá na no grupo da comunidade, dos avisos da comunidade e vão est lá os nossos avisos. Ah, oi, Wellington. É o seguinte, não, não precisa eh instalar Lamp, nada disso, porque a gente não vai trabalhar
          
          com eh bom, o eh Lamp, na verdade, a gente tá falando em Linux, né? O AMP objeto é a partir de Windows, mas o o AMP aí eh é PHP mais SQL e o A eu não lembro mais o que é, enfim. Não, não vamos não vamos aar isso, tá? Talvez, dependendo de como vocês vão trabalhar, vocês vão ter que ter eh Python, um Júpiter Notebook para deixar às vezes a coisa um pouco mais simples, mas não não tem nada de especial não, tá? E talvez vocês nem precisem fazer isso. Às vezes dá para resolver o que vocês querem só com um colab ou alguma
          
          outra ferramenta web. Com relação aos projetos, eh, eu mandei nos grupos ali um link, né? Coloquei, acho que tá no no na descrição dos grupos também, coloquei um formulário para que vocês coloquem suas dúvidas relativas aos projetos, tá? Ah, eu vou fazer um projeto X Y Z. Ah, como é que eu vou descobrir se eu tenho um produto que tá eh com substituição tributária? Ah, como é que eu faço para validar o XML da nota fiscal? Enfim, tem aquelas dúvidas eh que são mais de business, né? Ou seja, de como é que rola o fluxo de um documento
          
          fiscal dentro de uma empresa e esse tipo de coisa. A gente vai trazer o especialista para conversar com vocês, mas a gente precisa falar para ele sobre o que que ele vai conversar, né? Então, coloquem as dúvidas lá, a gente vai reunir tudo isso, mandar pro especialista. As dúvidas técnicas, dependendo do tipo de dúvida técnica, eu posso responder para vocês ou eu posso trazer alguém também para poder falar sobre essas dúvidas [Música] técnicas. Bom, eh, isso dito, assim, as orientações gerais estão tão terminadas.
          
          Ah, um detalhe que eu tava esquecendo com relação a Python, eu vi que uma grande quantidade de gente que respondeu o nosso a nossa pesquisa ou não conhece nada de linguagem de programação ou tem um conhecimento básico de Python. Procurem algum curso na web para pelo menos saberem um pouco sobre isso, tá? Lá no no no site do curso tem o link de um outro curso que a gente deu para junto com a Fly Education e lá tem duas aulas de Python. São bem básicas, mas assim tem muito link para vídeo, para material que vocês podem
          
          utilizar, tem indicação de livros, etc. Então, quem quiser estudar usando aquele materialzinho que tá lá, tudo bem. É um material de boa qualidade, tem bastante coisa interessante. Quem quiser fazer um cursinho qualquer na internet, no celular, enfim, aonde tiver o recurso, é bom fazer, tá? Ah, mas no meu grupo tem um cara muito bom de Python, eu não vou me preocupar com isso. Beleza? O que vai acontecer é que nas aulas aonde a gente apresentar código, o teu aproveitamento vai ser menor. Só isso. Legal.
          
          Eh, e também você não vai poder contribuir com o grupo no que diz respeito à parte de programação. Mas enfim, né, essa é uma decisão eh de organização dos grupos. Bom, terminamos as as orientações. A primeira coisa que a gente vai fazer, então, é complementar um pouquinho alguns conceitos pra gente ir fechando todo o racional de como é que nós vamos construir os nossos agentes, tá? Então, a gente já falou muito de LLM, etc., mas no fundo, no fundo, o que que é uma LLM, né? Uma LLM ou um Language
          
          model é uma rede especializada na produção, né, de originalmente de textos, mas atualmente a gente pode gerar texto, imagem e mais algumas outras coisas. eh que foi treinada a partir de um conjunto muito muito grande de informações, sejam elas textos, imagens, eh voz, né, ou ou material de áudio, dados estruturados, sinais, né? a gente tem LLMs, por exemplo, que são especialistas em eh análise de séries temporais, a Leghama da Vida, uma granite da IBM, eh tem outras que são especialistas só em textos. A gente tem os diffusions lá que
          
          me geram imagens, né? Tem até algumas LLMs que já são baseadas em diffusion para geração de texto. Enfim, né? Essa é uma tecnologia que tá tá em pleno desenvolvimento, mas, né, eh vocês também vão ver esse esse termo foundation models, né? Eh, esse foi um termo cunhado há algum tempo atrás que tá falando de modelos que foram pré-treinados com um grande volume e que servem de base, de fundação para você desenvolver toda essa capacidade de adaptação dos modelos, tá? Treinar um modelo é algo complexo, trabalhoso e muito caro.
          
          Então assim, eh, evita-se ao máximo treinar novos modelos, tá? Normalmente o que se faz é adaptar modelos. Então você treina um modelo a partir de outro que já tá treinado. Eh, você refaz uma parte do modelo, mas existem algumas algumas iniciativas para se treinar novos modelos. Enfim, eh, cada empresa que tá gerando os modelos adota lá a sua a sua estratégia. Só que o o ponto importante é que apesar da gente ter a impressão que a LLM ela tá sempre trabalhando com dados atualizados, isso não é verdade, tá? Um modelo ele só tem
          
          dentro dele os pesos, né? eh para poder fazer a geração dos resultados que me interessa. Mas esses pesos eles são relativos ao material que foi usado para treinar a a LLM, o material original que foi usado para treinar a LLM. E esse material ele está parado em um certo momento do tempo. Então é importante a gente entender isso, tá? que a LLM ela ela não ela não tem informações atualizadas, pelo menos em princípio, tá bom? e que ela também, essa capacidade de adaptação dela, ela também é relativa. E
          
          aí a gente precisa entender como é que a gente cuida dessa capacidade de adaptação. A pergunta que vem a partir de dessa dessa análise é o seguinte: "Então, como é que eu faço para melhorar o desempenho de uma LLM? forma mais simples e mais barata é fazer engenharia de prompt e trabalhar em cima do contexto. OK? Eh, essa a gente viu nas na aula com o professor Seabra, a gente já vinha falando alguma coisa relacionada à prompts, etc. A gente falou também, quando a gente tava falando lá em raciocínio,
          
          estratégia de raciocínio, a gente falou em finitan de modelo, tá? Fan é um negócio legal quando você quer especializar a rede em um conjunto de formações eh que você selecionou, né? Então você quer tornar ela ela bem especialista naquele conjunto, mas não é algo que a gente tá fazendo assim com em larga escala. é uma estratégia, mas não é uma estratégia de todo simples e nem eh a mais barata e a mais fácil de se fazer, principalmente porque para você fazer o Fine Tuno, você precisa ter um bom conjunto de dados para poder ajustar
          
          aquele pedaço da rede que te interessa, tá? E assim, e no limite, né, do que é o mais caro, mais difícil, mais complicado, é você retreinar o modelo e obviamente onde você vai ter a melhor qualidade de resposta, tá bom? Como a gente viu, prompt falou de fine e já falou de treinamento de modelo, ficou essa camadinha aqui no no meio que é o retrieval augmented que a gente não falou nada, né? Então, só vou introduzir o conceito porque se a gente olhar o nosso cronograma lá na frente a gente vai ficar um uma aula inteira só falando de
          
          hag, tá? Para quem nunca ouviu falar do assunto, que é o diabo do hag ou desse retrieval aumentage generation. Essa é uma técnica aonde a gente pega um um corpus ou mais de um, né, que eh corpus é latim, plural de de corpos é corpora, a gente pega lá um um ou mais corpos, né, pega uma um corpora e eu faço a decomposição desse corpus em em valores em vetores, tá? E guardo isso num banco de dados vetorial, tá? Essa técnica de fazer a a vetorização é o que vocês vão encontrar na literatura como embeding. Então, o
          
          que que eu faço? Eu pego os textos, transformo esses textos em números, tá? Mas números organizados de uma forma específica, tá? usando uma técnica chamada embeding. E esses valores numéricos eu armazeno num banco de dados que é preparado para receber esse tipo de informação, que é o que a gente chama de um banco de dados vetorial. Aí quando o meu usuário manda um prompt, uma pergunta, tá? Que que eu faço? Antes de levar essa pergunta para LLM, eu vou no banco de dados vetorial, aonde tem lá todos os os
          
          dados que eu preparei anteriormente. Uso uma técnica para tentar achar dentro daquele banco de dados vetorial qual informação é mais próxima da pergunta do usuário, o que teoricamente seria parte da resposta. recupero isso e coloco essa informação no contexto que eu vou enviar para minha LLM. OK? Feito isso, o meu contexto ele é muito mais rico, ele tem mais conteúdo e aí eu consigo eh fazer com que a LLM responda usando aquela informação adicional que eu tô colocando, que eu tô injetando ali dentro. Então eu não tô
          
          mudando a LLN. Eu só tô acrescentando mais informação do contexto, tá? Só que isso tem um um custo e esse custo ele é traduzido nos limites lá do tamanho do meu prompt. Meu prompt vai ficar maior. Então, eh, dependendo da LLM, do do tamanho de contexto que ela suporta, eu também não consigo mandar muita informação, tá? Mas isso aqui eu só trouxe pra gente poder ter um primeiro highlight. Outra coisa importante, tá? Se eu usei a técnica X para fazer embeding, essa técnica tem que ser a mesma técnica que a minha LLM espera
          
          receber, OK? Porque senão eu vou est passando um conjunto de valores para ela que ela não vai saber interpretar aquilo. Então você tem que fazer um casamento das coisas, tá? Esse é um cuidado adicional que tem que ser tomado, mas tomado esse cuidado, tranquilo, funciona muito bem. Com isso, a gente fecha esses quatro elementos aqui da engenharia de prompt, Hag, Fine Tun e o próprio treinamento de modelos, tá bom? Então, já que a gente sabe como a primoral o uma LLM, o próximo passo é a gente entender o que são agentes.
          
          Bom, o que que é um agente? Esse conceito de agente, ele veio originalmente do do conceito de de aprendizado, eh, não, de aprendizado supervisionado, aprendizado por reforço, tá? No aprendizado por reforço, que por sua vez vem da psicologia lá do do treinamento de reflexo condicionado, que que a gente faz? a gente pega um agente de software, esse agente, né, entre aspas, ele decide alguma coisa e aí em função da decisão dele, ele pode receber ou uma recompensa ou uma penalidade. Esse é o conceito básico inicial de um de um
          
          agente no âmbito de aprendizado por reforço. Legal? Então, teoricamente, que que seria o agente? é um sistema inteligente que interage com um ambiente e em função dessa interação com o ambiente, ele recebe recompensas e penalidades e a partir daí ele troca a sua forma de realizar aquela atividade para que ele maximize a recompensa, OK? Então, por exemplo, quem tem aquele aspirador que fica eh caminhando pela casa lá, aspirando eh sozinho a casa, aquele aspirador, ele aprende como é que é o ambiente à medida que ele vai
          
          caminhando, que ele bate nas coisas ou que ele eh alguns têm câmera, né? Então, aonde a visão computacional dele detecta obstáculos, mas de qualquer forma ele vai criando um mapa do ambiente e vai aprendendo quais são as movimentações que ele pode fazer, que vai maximizar o resultado dele, que no caso é aspirarpó. Essa técnica é o que a gente chama de aprendizado por reforço e ela pode ser uma coisa que vai sendo, vai acontecendo de forma contínua, tá? Ao contrário do que acontece com as LLMs, que a gente treina, fechou, acabou. No
          
          aprendizado por reforço, o agente pode estar continuamente aprendendo. Então, se a gente tiver falando de um agente que tá trabalhando no ambiente físico, né, o caso do aspirador de pó, ele é um robozinho, né, um robô, um carro autônomo e outros equipamentos que podem estar agindo, interagindo com com o ambiente no ambiente digital. Eh, se vocês procurarem, vocês vão encontrar eh agentes que, por exemplo, jogam os joguinhos da Tari lá, aqueles joguinhos antigos, né, que eles eles sempre repetiam a mesma sequência, mas
          
          você põe o software para aprender, o software com o tempo aprende como é que ele como é que ele faz para jogar o joguinho, né, do Atari, Super Mario e outros, né? Eh, e a técnica que o pessoal tá usando para fazer isso hoje, se vocês forem pesquisar um pouquinho, vocês vão ver que é uma DeepQue Network, tá? Que é uma rede neural, mas é uma rede neural voltada para eh resolver problemas de aprendizado por reforço. A Siri e outros assistentes também usam eh esse tipo de abordagem. O Alfa Go, ele aprendeu a
          
          jogar GO, eh, usando técnicas de aprendizado por reforço também. As últimas redes dessa mesma linha aí da família, né, do Alfago, também usa intensivamente aprendizado por reforço e assim por diante. E quando a gente tá falando, por exemplo, de interação de de ser humano com agente, a gente pode ter chatbots que aprendem eh como é que as pessoas se comportem. Legal. Bom, entendido o conceito de agente, tá? A gente pode pensar assim: "E o que que acontece se eu tiver um agente trabalhando com processamento de
          
          linguagem natural, né, ou uma LLM, porque no fundo uma LLM nada mais é do que uma evolução das técnicas eh tradicionais de processamento de linguagem natural. A gente consegue dividir isso talvez em três categorias, tá? Vou imaginar o agente mais simples que ele consegue entender uma parte ou recuperar, usando uma técnica qualquer, recuperar pedaços do de um de um diálogo e aí eh coletar essas essas essas partes, montar um novo texto, né, e produzir uma resposta, tá? O o caso mais antigo que a gente tem
          
          desse tipo de agente, que é um agente bem simples, é o o Eliza, que foi o primeiro chatbod construído, eu não lembro mais, mas foi na década de 60, tá? 60 e alguma coisinha. Eu acho que até tem aqui no na telinha, enfim, essa esse print aqui é um print da tela original lá do Eliz. Eh, e ele usava lá uma técnica de psicologia interessante, mas assim, ele era um programa construído com um monte lá de de eh IFS, né, de de sentenças para ele tomar decisões, mas era uma coisa programada, decisão a decisão, OK?
          
          Eh, e ele simplesmente pegava texto e respondia texto, né? Um outro exemplo para isso é uma DeepQ Network, mas que usa redes recorrentes. Não vamos entrar no mérito da questão, é só para vocês saberem que tem esse tipo de de coisa, tá bom? Ah, inclusive teve um caso interessante no no curso, no curso de redesivas que a gente fez o ano passado, uma da das tarefas dos alunos era reproduzir o Ela usando uma LLM. foi assim fantástico os resultados que que a gente obteve, o pessoal conseguiu reproduzir direitinho
          
          o software, deixar ele até um pouco mais inteligente e etc. Foi muito legal, foi uma experiência muito boa. O segundo nível seria um um uma LLM, um agente que usa uma LLM, tá? Mas ele usa LLM só para tomar a decisão eh de qual ação ele deve executar. Então, eu não sei se vocês viram uns tempos atrás, a a canen da da Google era um robozinho que você pedia para ele executar uma ação e ele ia lá e fisicamente executava essa ação. Uma ou LLM planner, que também você diz para ele o que você deseja, ele
          
          monta o planinho lá para executar as ações físicas para para realizar o que você quer. E o terceiro tipo de agente que a gente poderia ter, que seria o terceiro nível, né, o mais sofisticado, é onde a gente tá hoje, aonde no aonde a gente usa a LLM, não só para agir, né, para definir uma ação, mas para raciocinar qual que é a melhor forma de executar aquela ação. Então, é um agente que ele planeja e age. Vamos tentar entender isso um pouco melhor. E para isso, vamos usar o exemplo mais simples que a gente tem,
          
          que é um um chatbot que responde perguntas, né? Um um chatbot de question, tá? Aqui os exemplos que eu usei, eu peguei o eu usei o Gemini da Google, tá? Então, as respostas quando tiver aqui são respostas que eu obtivo usando a interface eh do Gemini, a interface aberta para todo mundo, tá? Então, por exemplo, eu mandei lá: "Olá, como vai?" A resposta que eu tive: "Estou muito bem, obrigado por perguntar". E aí mandou mais um monte de coisa, como a gente já viu lá com com Seabra, as as LLM são tagarelas,
          
          né? E tem dois motivos para elas ser tagelas. Primeiro porque é da natureza delas e segundo porque você paga pelo que ela responde. Então quanto mais tagarela ela for, mais você paga. E essa é a ideia que tá por trás disso. Mas enfim, quando você faz uma pergunta dessa lá, como vai e recebe uma resposta, ah, eu estou bem, isso é uma inferência simples. É aquilo que a gente já viu das das LLMs, que é, ah, eu vou prever qual que é a próxima palavra a partir do input que eu tive do usuário. E é uma uma resposta, é até uma pergunta
          
          retórica, né? Olá, como vai? Ah, tô bem. Às vezes o cara não tá, mas ele fala que tá bem. Enfim. Uma outra pergunta. As aves de Maria põe 16 ovos por dia. Todos os dias ela come um no café da manhã e assa bolos, consumindo mais quatro ovos. Ela vende o restante por 50 centavos cada ovo. Quanto ela ganha por semana? Tá? Esse é o tipo de coisa que requer raciocínio. Ou seja, não basta só eu eu tentar produzir a próxima palavra, eu tenho que decompor esse problema em partes e aí eh gerar uma resposta,
          
          tá? Agora, e se eu perguntar assim, quem é o papa atual? E aqui, gente, não é não tem nada a ver com religião, tá? É só porque foi um evento recente, né, que a gente teve aí um novo papa. Podia ter perguntado quem era o presidente dos Estados Unidos, mas isso já faz um pouco tempo. Eu queria pegar uma uma coisa que fosse bem recente. Isso requer conhecimento atualizado, porque exatamente a gente teve a ocorrência da substituição do Papa atual devido ao falecimento do Papa anterior, tá? Então, esses são dados que são eh relativamente
          
          recentes e que, provavelmente a a LLM não conhece, porque ela foi treinada até um certo período do tempo, tá? E se eu coloco ainda, né, qual é o quago número da sequência de Fibonacci? Esse essa pergunta ela não só requer lá um planinho para poder eh executar isso, mas ela implica em processamento, porque eu posso até falar como é que calcula o número da sequência de Fibonacci, mas eu vou ter que ficar iterando ali para conseguir calcular qual que é o quagéso. Então vocês vem que eh um simples question pode gerar um monte de
          
          derivações interessantes, né? E aí vamos entender como é que são essas estratégias que a gente pode adotar ou que as LLMs adotam para resolver os problemas, tá? Aquela do da pergunta simples a gente já sabe, né? Eh, olá, como vai? Ah, vou bem. Isso é uma consequência natural da própria estrutura da da LLM. No caso da da Maria, né? Que que acontece? A LLM, ela vai ter que passar por duas etapas. uma etapa de raciocínio e uma etapa de resposta. A etapa de raciocínio, inclusive, é interessante lá no no Gemini, quando você pede para ele
          
          abrir e mostrar a a etapa de raciocínio é feita em inglês, tá? Então ele ele chega à conclusão que ele tem que calcular a quantidade de ovos que as galinhas botam, quanto a Maria consome, o número de de ovos que sobram para serem vendidos e aí eh calcular o valor da do quanto ele recebe. Aqui aqui tem um errinho. Eu tinha feito quanto ela ganha por dia, depois alterei a a pergunta para quanto ganha por semana e não copiei a resposta, tá? Mas não tem problema nenhum, finge que é por dia e não por
          
          semana. Bom, e aí a etapa da resposta, ele fala que Maria ganha R,50 por dia. E aí ele explica como é que calculou. Então, pôs 16 ovos, ela come um e gasta mais quatro, ela gasta cinco, né? Então sobram 11 ovos a 50 centavos cada ovo, 5,50. Se fosse por semana, era só multiplicar isso por sete. Enfim, eh, mas esse é um raciocínio onde a LLM teve que realmente pensar em como ela ia gerar a resposta, tá? No caso do Gemini, eu podia ter pedido para ele eh explicar detalhadamente cada um dos passos, que é
          
          aquela técnica lá do chain of thought. Não foi necessário, ele já fez isso naturalmente, mas dependendo da situação, você vai ter que fazer isso, tá? Mas é um raciocínio simples ainda. Com relação à questão do processamento, olha que interessante, eu mandei a pergunta e eu obtive essa resposta aqui, ó. Para encontrar o quº número da sequência de Fibonacci, hã, F49, se o primeiro número na f0 foi igual a zer, precisamos usar a regra que cada número a soma dos dois anteriores, começando com zero e 1.
          
          Calcular isso manualmente seria extremamente trabalhoso e propenso a erros. No entanto, podemos usar um programa simples para fazer isso de forma eficiente. E aí a RID escreveu um programa Python, executou o programa Python e me trouxe a resultado, o resultado que eh o quº número da sequência de Fibonacci é esse número aí que eu não vou me aventurar a ler, né? Eh, porque é um número bem grande. E aí aqui só para brincar com os os nossos colegas portugueses que estão aqui assistindo a aula, né? Gente, aqui
          
          no Brasil usa um milhar curto, lá eles usam milhar longo, então dependendo do que eu falar, vai soar estranho para eles. Então, eu vou me abster de falar, tá? Enfim, e aqui a gente já entende que dependendo da estratégia, vale a pena realmente você lançar a mão de alguns recursos externos, tá? E aí aqui a gente tem um outro problema, né? Eh, eu fiz a pergunta bem maliciosa pro pra rede, tá? para ver como é que ela ia me responder. Ó, baseando-se apenas no conhecimento existente em sua base original de
          
          treinamento, responda: "Quem é o papa atual?" E aí a rede me respondeu o seguinte: baseando-me exclusivamente o conhecimento que possui na minha base de treinamento original, o papa atual seria Papo Papa Francisco, o Jorge Mário Bergoglo. E de fato, né, isso deve est parado no tempo, essa essa base de treinamento em 2025, 2025, não, perdão, 2023, 2022, enfim. E naquele momento o papa atual era o o Papa Francisco, tá? Se eu não tenho o conhecimento atualizado, que que eu posso fazer, né? Lembrando que a gente falou, eu posso
          
          usar o Hag, vou numa base de conhecimento, num corpora, né, que eu tenho, faço a recuperação de dado e recomponho o meu o meu prompt para que eh a rede possa fazer resposta. Mas nesse caso aqui em particular, e se o meu conjunto de dados não tem essa informação, como é que eu vou fazer? Tá? Porque uma coisa é eu trabalhar em cima de de dados que estão de alguma forma mais atualizados, mas estão parados no tempo. Mas isso eu preciso de um dado que é muito recente, né, que aconteceu há poucos há poucos minutos ou um
          
          streaming que tá a coisa tá rolando em tempo real e etc. Haag não vai resolver o meu problema. Aí é o momento onde eu tenho que lançar a mão de ferramentas. Então eu tenho que prover ferramentas paraa minha LLM de forma que ela execute ações. Então quando a gente fala que eu eu vou ter um um agente, eu tô falando de uma LLM provida de raciocínio, capacidade de raciocínio e ferramentas, tá? E que tipo de ferramenta? uma ferramenta de busca para encontrar uma informação na internet, uma ferramenta
          
          para execução de script, que é o que a gente viu ali atrás, né? No caso do Fibonacci, gerou o programa, o código fonte em Python e executou para obter o resultado. Uma ferramenta que acessa banco de dados, faz query, uma calculadora, né? ou posso buscar um modelo específico para tratar uma característica eh distinta ali do do da minha solução. Por exemplo, eh eu tenho uma série temporal e eu tô usando uma LLM que é boa para texto, mas eu quero usar uma outra que é especialista em fazer predição de série temporal e assim
          
          por diante. Acessar o sistema de arquivos, copiar arquivo, apagar arquivo, mover arquivo e etcim, tá? Posso ter n ferramentas. E aí isso nos traz a um novo conceito, né? Então eu tenho o conceito só de raciocínio e tem o conceito de ação, tá? Então assim, quando eu penso só no raciocínio, eu posso pensar em alguma coisa que remonte, né, o nosso chass. De tal forma que quando eu tenho L, LLN, que ela tá detalhando a forma como ela ela vai raciocinar alguma coisa ou como ela pretende, né, responder algo, tá? Eu
          
          tenho ali os meus indícios da capacidade de raciocínio da LLE. Isso é legal porque é flexível, é bem generalizável, mas ele não tá ligado a uso de ferramentas ou ainda ele não me permite o uso de conhecimento externo. Quando eu uso Hag, né, e uso código e ferramentas, o que que acontece? A minha LLM determina ações que atuam no ambiente e ela vê o resultado dessa ação, mas o RAG com ferramentas pura e simplesmente não implicem raciocínio. Então eu tenho aqui nesse momento, né, um um uma LLM que ela é
          
          flexível, é generalizável para obter eh conhecimento externo, realizar cálculos, gerar feedback, etc. Mas ela não está raciocinando. Beleza? Lembrem-se dessas duas características, né? Raciocínio e a capacidade de usar recursos externos. Quando eu junto as duas, tá? um modelo, por exemplo, de agente, e tem mais de um modelo, trouxe só esse como um exemplo, a gente pode ter o que a gente chama de react, ou seja, um agente que é fundamentalmente uma LLM, que tem a capacidade de eh decompor alguma coisa de forma racional para
          
          obter uma resposta, mas que também faz uso de ferramentas para receber eh conteúdo que ela não tem ou executar ações que ela não tem capacidade de executar, ok? E aí, a partir disso, usando o raciocínio e executando ações e observando o resultado das suas ações, a LLM pode eh responder questões ou realizar ações muito mais eh sofisticadas do que cada um daqueles casos separadamente, seja do chaft ou só da LLM com algumas ferramentas, tá? Então, basicamente o que que acontece dentro desse modelo React? Quando você
          
          coloca alguma coisa para uma LLM executar, ela primeiro ela planeja o que ela quer fazer, aí ela lança a mão dos recursos que ela tem disponíveis, né, das ferramentas e dos passos que ela determinou que ela vai executar. Executa, colhe o resultado, ou seja, é a etapa de observação, né? observa o resultado daquela ação, analisa se aquele resultado está adequado, se não estiver, ela cria uma nova estratégia ou lança a mão de alguma outra ferramenta ou tenta executar aquilo novamente até que ela consiga
          
          chegar num resultado que é adequado para ela poder gerar a resposta pra gente. Legal? Então vocês veem que esse é um modelo muito mais sofisticado do que o que a gente vinha discutindo até agora com prompt e e talvez com uso de alguma ferramenta. E aí o que que acontece quando a gente tem esse tipo de coisa? Eh, a gente tem a LLM sendo capaz de decidir coisas. Então, por exemplo, quando eu perguntei quem é o papa atual, o que que o o Jemin me falou? que o papo atual é o Leão eh 14, né? E aí colocou mais
          
          algumas algumas informações adicionais, né, que eu não queria, mas tudo bem, ele trouxe. Mas eu perguntei para ele assim: "Como é que você conseguiu essa informação?" Olha que interessante a resposta. A minha capacidade de acessar informações mais recentes, como a eleição de um novo Papa em 2025, vem da minha capacidade de me conectar e pesquisar informações atualizadas em tempo real na internet. Quando a pergunta é feita de uma forma que requer conhecimento além da minha base de treinamento estático, eu sou
          
          capaz de utilizar a ferramenta de busca na web para encontrar e apresentar informações mais atualizadas disponíveis. Foi assim que obtive o nome do Papa Leão 14, os detalhes sobre a sua eleição e origem. Então o que que acontece? ALM recebeu a pergunta, entendeu que ela não tinha informação atualizada, bolou uma estratégia para recuperar essa informação, utilizou uma ferramenta de busca para poder buscar essa informação mais atualizada, validou-se aquela resposta atendia a minha pergunta e aí me gerou a resposta.
          
          Legal? Isso basicamente é um agente trabalhando, é muito mais do que simplesmente uma LLM, tá? é um agente eh com rede generativa, né, com com LLM, atuando para gerar respostas inteligentes pra gente e extremamente adaptável, se a gente pensar nesse caso. Bom, então o que que acontece quando a gente fala em QI? A gente tá falando de agentes que estão empoderados, né? De agentes que t muito mais poder do que a própria LM, tá? Só para fixar bem o conceito, né? Então, o modelo eh simples de um agente, esse
          
          aqui é uma imagenzinha que tem lá na no material da Microsoft, ele é uma LLM, aonde ela é capaz de analisar o estado de alguma coisa. Entendam por estado contextos passados e o contexto presente e é capaz de manter esse resultado do contexto para utilizar posteriormente e é capaz de acessar ferramentas de tal modo que essas ferramentas alterem o seu contexto. E aí a partir desse loop de processamento ela consegue gerar respostas ou executar ações pra gente. Legal. Mas Cels, e ferramenta, que diabo de
          
          ferramenta é essa aqui? Tá bem pequenininho, né? Mas eu peguei, por exemplo, lá no Langchain, tem uma pagininha que só fala de ferramentas lá. Deve ter umas 100, 150, sei lá, 200 ferramentas. Tem ferramenta para fazer pesquisa na internet, ferramenta para acessar banco de dados, ferramenta para fazer cálculo, ferramenta para acessar o sistema de arquivos, ferramenta para fazer um monte de coisa, para acessar a rede social, para acessar Wikipedia, enfim, ali tem um monte de ferramentas. E aí você tem a técnica correta para
          
          poder fazer o seu agente ligar-se à ferramenta ou pelo menos para você disponibilizar a ferramenta pro seu agente, tá? A outra telinha ali é do N8N, que também tem um caminhão de ferramenta, né? É que ele não chama necessariamente de ferramenta, tá? ele usa um um outro termo para isso, mas ali a gente consegue facilmente reconhecer que é um conjunto de ferramentas que tá disponível pros seus os agentes que você constrói usando ele. E que que acontece quando a gente pensa, né, de em agente com ferramenta?
          
          Esse aqui é um exemplo eh que eu busquei lá na Microsoft de um agente para falar como é que tá o clima em algum lugar, tá? Então como é que basicamente funciona esse agente? a pessoa perguntar como é que tá o clima, sei lá, em em caixa pó mirim, tá? Aí o o meu agente vai, recupera a informação, né, de clima do de cachapó mirim e manda um e-mail pra pessoa. Como é que você faz isso? Ó, inicialmente você tem que você tem que ter um um prompt explicando pra tua LLM o que que ela tem que fazer, tá? Então, ó, você é
          
          um agente que responde questões sobre clima. Você também vai enviar as informações de clima em um e-mail que faz fornecido, né? Um endereço de e-mail fornecido. Você, se você, se for pedido que você envie a ifil, tá? Se for pedido que você mande a informação por e-mail, pergunte o endereço de e-mail caso ele não tenha sido fornecido. Legal? Formate a sua resposta em uma lista de bullets. Lembram lá das técnicas que a gente viu com sebbra, né, do passef, etc. faça, né, crie respostas concisas e úteis, mas use um tom de de eh de
          
          conversação, né, um tom de diálogo conversacional e eh amigável. Inclua sugestões como leve um um guarda-chuva ou use agasalhos, etc. Tá? Então aqui você explicou paraa LLM quem ela é, o que ela faz, né? Explicou pro agente quem ele é, o que ele faz e como é que ele ele vai se comportar. E aí você tem na própria definição do agente as ferramentas que ele tem. Então ele tem uma ferramenta que é essa geteather, que ela vai pegar as informações de clima atuais para aquela localidade que você descreveu e
          
          tem a ferramentinha que manda e-mail. Isso é o suficiente para poder gerar esse resultado que foi imaginado. OK. Ah, mas e se não for lá na usando a ferramentinha da Microsoft EUR, tal, né? Tem alguma outra? Esse aqui é o mesmo caso que eu peguei, mas usando a N8N. E olha que interessante, tá? Eh, se a gente for olhar o o prompt do agente, tá? Ó, você é um agente útil, ah, com uma ferramenta de para recuperação de clima e uma ferramenta para acessar o a Wikipedia. encontra latitude e longitude de uma
          
          localização e usa essa informação na ferramenta de clima para obter o clima corrente. Se a pessoa fizer uma outra pergunta qualquer que não seja o clima, então responda usando a informação contida no Wikipedia. E aí aqui a gente dando um zoom naquele pedacinho da da das ferramentas, ele tem duas ferramentinhas. Uma ferramenta que faz uma requisições usando, né, eh protocolo HTTP para obter a informação de clima e tem a outra que acessa Wikipedia para responder perguntas assim de uma forma mais genérica, tá?
          
          César, não sei, para ser bem sincero, tá? O o material que eu peguei lá da Microsoft, quando eu tava olhando, né, essas essas gerações de agentes, ele tá em inglês. Mas assim, no fundo fica aqui um conselho geral, tá pessoal? Como a gente tá trabalhando com tecnologia que ainda é muito de vanguarda, a maior parte do material de qualidade que vocês vão encontrar vai tá em inglês, tá? Então assim, se você não tem facilidade com inglês, não se sente confortável com a língua, eh você pode usar uma ferramenta
          
          de tradução. O próprio site da Microsoft tem essa opção lá para você ir traduzindo à medida que que você vai usando. Mas assim, nem sempre a tradução fica 100%. principalmente quando a gente fala em material técnico. Aqui no Brasil a gente tem o hábito de de manter, né, eh, muitos termos em inglês na sua forma original e incorpora isso, eh, no uso de dia a dia e depois acaba virando verbo, né? Ah, é isso aí, Ailda. Na verdade, não é bem na produção do prompt, tá? Depois, quando você compõe o o pacote inteiro,
          
          você descreve para tu LLM quais as ferramentas que ela tem disponível para que ela tome a decisão de qual ferramenta usar, OK? E aí daqui a pouco a gente vai ver alguns frameworks. Existem os frameworks que tornam essa essa tarefa menos dolorosa, tá? Aqui no caso da N8N, ela é uma ferramenta low code, então você vai arrastando caixinha, tá? E e aí a ligação dessas caixinhas já resolve para você como é que você conversa, né? O agente conversa com a ferramenta. Quando você vai escrever código na mão, aí você tem que
          
          realmente descrever as coisas. Mas não é assim um bicho de sete cabeças, não. É um bicho de cinco cabeças, tá? Dá para dá para sobreviver. Bom, e aí é o seguinte, então, tá? Então, eu já entendi que uma LLM com ferramenta e capacidade de raciocínio é um agente. Eh, eu posso usar agente para resolver problemas razoavelmente complexos. Na verdade, se eu tiver até um conjunto de agentes, né, eu posso utilizar alguns agentes especialistas para resolver a uma parte das minhas necessidades e alguns agentes mais
          
          generalistas que vão lançar mão de ferramentas ou outros agentes para poder responder o que eu quero, tá? Eh, ou executar as ações que que a gente determinar. Mas assim, eu preciso poder planejar essas coisas, né? Então, como é que eu faço para planejar um agente, para executar uma atividade qualquer para mim? A primeira etapa é você decompor eh o que você quer, né, em funções menores ou em tarefas menores, tá? Então você vai quebrar aquela tua necessidade em tarefas mais simples, de tal forma que você possa ter os seus
          
          agentes executando coisas simples que são fáceis da gente eh verificar, analisar se aquilo tá sendo o que eu quero e garantir que aquilo tá alinhado com os objetivos do do que eu tô procurando, tá? Existe uma questão importante que é definir qual é o nível de autonomia que o meu agente tem. Então assim, ah, ele vai ser um copilot, se ele é um copiloto, então ser humano, tô executando as coisas e o agente tá me apoiando. Se é colaborativo, eu, humano e o agente executamos parte das atividades. Se é supervisionado, o
          
          agente executa as atividades, mas eu, humano, dou a palavra final. ou autônomo, o agente se vira e resolve tudo sozinho, tá? Vou ter que projetar quais as capacidades o meu agente ou os meus agentes vão ter. Então, qual é a LLM que eu vou usar? Ah, eu vou usar a Llx, vou usar o Grock, vou usar o o ah, sei lá, vai o uma da Open Ai, vou usar o Gemini, a o Flash, não sei o que, das quantas, o Ken, o Parará, Dipsic, R1, R2, R3, RN, enfim, né? Eh, qual LLM eu vou usar? E aí vale a pena você fazer alguns testes
          
          antes para ver se ela dá o tipo de resposta que você deseja. quais ferramentas, né, eh, que eu pretendo disponibilizar para essa minha LLM, para que ela execute as ações que eu tô, aquelas tarefinhas que eu tô eh eh quebrando lá em elementos mais simples, tá? Quais frameworks eu pretendo utilizar para poder colocar o meu agente, né? Eu vou usar um um Langchain, vou usar um N8N, enfim, né? como é que essas ferramentas elas vão ser acessadas pelo meu agente ou pelos meus agentes? Como é que esses
          
          agentes vão conversar, né? E aí aqui fica a dica. Eh, o protocolo MCP que foi lançado pela Antropic, ele visa resolver alguns problemas quando a gente tá criando esses agentes que visa resolver problemas relacionados à memória, a à manutenção de contexto e, principalmente padronização das mensagens entre ferramenta e agente, tá? E vice-versa. OK. Ah, e planejar interação. Se eu tiver um sistema multiagente, como é que eu vou fazer um agente conversar com outro, tá? Eh, eles vão estar dentro do mesmo bloco
          
          de código ou o meu agente vai ser um serviço e onde o agente A acessa o agente B, como é que eles vão trocar a informação? Como é que eu sei que tá certo? Tá. E aí, para quem tá antenado aí nas novidades, o Ha, que é um um protocolo que tá sendo desenvolvido pela equipe da Google, que é muito recente, inclusive ele deve ter o quê? Talvez um, dois meses que foi lançado, ele visa resolver esse problema da comunicação entre agentes. Ah, mas o MCP também resolve algumas coisas nesse sentido. Resolve. O
          
          Hway ele é uma evolução ou uma camada eh mais complexa, né, que é colocada para para resolver alguns problemas que o MCP não resolvia, tá? Então fica a dica para quem quer estudar isso mais a fundo. Estuda as frameworks ou pelo menos uma framework, estude ela bem. Eh, dê uma boa olhada no protocolo MCP e acompanhe a evolução do Hway, porque o Hway tá bem no comecinho. Bom, outra coisa que você tem que planejar no seu agente, esse seu agente ele vai sempre fazer a mesma coisa, OK? Se adaptando ali eventualmente a alguma
          
          diferença nos dados, etc. Ou ele vai ter a capacidade de se adaptar. E se ele vai ser capaz de se adaptar, que tipo de adaptação que você vai permitir para ele, tá? Eh, a gente tem aqui listada três, adaptação contextual, quando essa mudança no comportamento do agente, ela acontece em função de informações que ele tem no contexto, tá? Seja porque veio eh já passada no contexto ou por causa da própria inferência dele. Uma adaptação paramétrica, tá? ela permite a atualização da relação entre os estados e as ações. Então, à
          
          medida que os estados vão se modificando, eu também modifico as ações que têm que ser tomadas. ou uma atualização, uma adaptação reflexiva a partir do raciocínio do do meu agente, à medida que ele vai refletindo sobre os resultados que ele obteve e como ele obteve esses resultados, ele pode se adaptar para poder resolver o seu problema de uma forma diferente e eh fazer o planejamento para o monitoramento e tratamento das exceções, tá? Porque é o seguinte, essas coisas dão erro. Quando você coloca um agente, uma um componente
          
          de software para falar com outro, às vezes você pode estar com um link quebrado, um servidor que tá fora do ar, uma pesquisa que você foi fazer num site e não retornou nada, né? ou retornou uma mensagem de erro dizendo que você não pode eh procurar aquela coisa ali, você foi fazer um cálculo matemático e aí no meio da coisa deu uma divisão por zero e isso gera uma exceção e o teu código quebra assim pode acontecer n situações e aí você tem que ser capaz de monitorar esses problemas, tratar essas exceções e
          
          e dar pro seu agente a capacidade de se eh adaptar a esse tipo de de questão, tá? Ah, assim, ó, Artur, na minha opinião, usa MCP, que é a melhor forma de você conseguir trabalhar com isso, porque ali você vai criar o promp direitinho, eh, vai ter a a definição das tools direitinho, tá? E e vai poder fazer essa conversação entre os agentes. Legal. Ó, Rogério, não é que assim o pai tá indicado para treinar uma LLM, tá? O que acontece é que já há muitos anos a comunidade que trabalha com inteligência
          
          artificial usa B. Então tudo que está de de mais recente, eh, as ferramentas mais interessantes, etc., elas são eh preparadas para rodar com Python, OK? a gente vê assim pouca pouca movimentação, pelo menos não é o mercado que eu acompanho de perto, mas eu vejo menos eh atividade para Java ou para C#ARP, então o Python acabou sendo a linguagem escolhida pelo mercado, sabe? É aquela coisa assim, ah, por que que todo mundo usa Windows em vez de usar Linux? Porque cara, né? É aquilo que tava lá. A pessoa começou trabalhando
          
          com Linux, aprendeu a Linux, perdão, começou trabalhando com Windows, aprendeu a usar o Windows. E aí ela achou o Linux esquisito. Tem disco no mercado de montão, tá? Ah, ó, Maurício, existe um grande interesse do mercado na construção, né, na contratação de agentes inteligentes, tá? O que acontece é que existe também muita desinformação. Então assim, muitas empresas eh acham que esse é um negócio assim, bala de prata, que você vai pôr um treco lá, esse treco vai aprender a rotina da empresa e sair fazendo as
          
          coisas sozinho, tá bom? Eh, tem mercado, tem, tem espaço, tem, dá para ganhar dinheiro com isso, dá. Tem gente interessada, tem, mas como toda eh tecnologia que ainda está em desenvolvimento e que tá passando pela fase de hype, tem muita informação errada, muita informação distorcida e as empresas, né, os executivos que estão nas empresas não estão sendo alimentados com as informações corretas. Isso costuma gerar uma grande decepção do dos executivos quando eles eh são apresentados paraa realidade no I
          
          crua, tá? Mas isso vai ficar eh é uma coisa que vai ficar e não tem retorno, tá? Ah, eu fiz essa separação, Aldenir, porque é o seguinte, um framework é um conjunto de bibliotecas ou uma biblioteca que você usa no teu código, OK? Eh, a ferramenta ela já tem aquele ambiente para você poder criar tudo. E no caso específico, por exemplo, do da N8N L flow, são ferramentas do tipo arrastar e soltar, sabe? Você tem componentes que você arrasta e vai ligando um componente na no outro e você define lá o teu agente. Só por isso que
          
          eu fiz essa essa separação, tá bom? Eu não vou entrar no detalhe porque senão a gente vai ficar aqui um tempão falando, falando, falando, né? E e não vamos chegar assim em grandes resultados. Mas eu já deixei separadinho aqui para vocês essas principais ferramentas, né? Que que é a ferramenta, quais as vantagens dela, quais as desvantagens. Então vamos pegar esse caso aqui do Autogên, é um framework da Microsoft, beleza? Então você já sabe que quando você usar o Autogen, de certa forma você tá sendo direcionado pra
          
          ferramental da Microsoft, tá? Tá, mas ele tem suas vantagens lá, ó. Posso fazer colaboração entre agentes. Isso é legal, é flexível, legal, né? Qual que é uma desvantagem? Ah, ela é complexa, tanto para projetar e depurar. A interação entre os agentes. É um negócio que pode não pode ser tão simples. Curva de aprendizagem, você tem uma curva de aprendizagem dilatada porque você precisa aprender a desenhar sistemas agênticos. Então tem vantagem, tem as suas características boas, tem uma Microsoft
          
          por trás que te garante também algumas coisas interessantes, mas né? Ah, vamos pegar uma outra aqui. Pidentic. Pidentic é uma biblioteca. Se é uma biblioteca é um cara que eu vou colocar lá no meu código Python Strong, não sei o qu taralá, tá? Tem suas vantagens e desvantagens. A principal desvantagem, ó, ela é uma Python Centric. Eu só posso usar Pidentic para projetos em Python. Ah, mas eu quero fazer em Java. Hum, sinto muito, companheiro, não vai dar. Que que dá para fazer? constrói um pedacinho em
          
          Python, transforma isso num serviço, por exemplo, que você vai deixar disponível dentro de um Docker. E aí a tua aplicação Java via um um uma chamada a um serviço REST, ela vai lá e consome o resultado daquele teu código Python. É uma alternativa de arquitetura de sistema, tá? Ah, mas ficou muito complicado. Eu não sei trabalhar com Docker, não sei eh, inscrever serviço em Python, etc. Esse é o desafio que todos nós enfrentamos no dia a dia, OK? E principalmente porque a gente tem eh um caminhão de tecnologia à nossa
          
          disposição, mas assim, entender esse caminhão é complicado. Obrigatoriamente tenho que ter um software para usar mais de um agente ou consigo fazer uma UNIC. Ó, Sérgio, é o seguinte, dá para você colocar vários agentes dentro do mesmo bloco de código, tá OK? Eh, aí é uma questão de desenho de arquitetura do teu agente. Como é que você pretende que ele seja do agente ou dos agentes, tá? Você pode ter o bloquinho de código lá com vários agentes. E aí, como é que você vai fazer a chamada entre eles? que provavelmente
          
          você vai ter que aprender nesse caso, eh, trabalhar com programação assíncrona, porque você vai eh disparar a ação do agente e e vai ter que ficar esperando, mas não é aquela espera clássica de programa que seja, o programa A chama a função B e fica ali morto, tá? essa essa essas questões, eu não sei se a gente vai chegar nesse ponto com esse grau de detalhe, mas quando a gente tiver falando de Python, né, a aula de Python que o o professor Marcelo deve dar para vocês, principalmente dessa parte de
          
          desenho dos agentes, a gente deve entrar nesse nessa seara, tá? Ó, assim, das frameworks, essas que eu coloquei aqui para vocês, todas elas são interessantes. Qual que é a que tem tido a maior o maior desenvolvimento, só que ela também, por ser a mais antiga, a que tem mais desenvolvimento, ela ela é mais complexa para usar, é o Long Chain, tá? Então assim, ó, eu sou eu sou um programador Python, me sinto bem, confortável, não tenho problema em trabalhar com essas coisas. Langcha MCP. OK. Bom, claro, senhor
          
          Carlos, o o que acontece é o seguinte, tá? Eh, se você tiver, por exemplo, um um olhama, ah, deixa eu pegar aqui o nome dele agora, fugiu, Jesus, um olhama da vida, tá? E existem outras outros aplicativos que você pode colocar. O Olhama, o que que ele faz? Ele é um software que você instala localmente e aí você pode disparar o uma uma LLM, né? fazer o download da LLM, rodar ela localmente e aí você coloca ele respondendo pro teu agente. Que que você consegue com isso, né? Reduzir absurdamente o teu custo com
          
          tokens. Qual que é o a contrapartida disso? Você tem que ter um hardware bom com placa eh com GPU. dependendo da complexidade do que você tá fazendo, vai demorar muito para rodar localmente, OK? E eventualmente não vai ser escalável, mas você pode, por exemplo, construir uma arquitetura de software onde a LLM que você vai executar, ela pode estar local ou pode estar na nuvem. E aí, dependendo de alguns alguma coisa que você liga, desliga lá dentro dos teus software, você vai para um lado ou vai pro outro, OK? É uma, de novo, né?
          
          São decisões de arquitetura de sistema. Ah, você tem as duas situações, tá, Helbert? Eh, quando você tem alguma coisa assim, você manda pergunta e você tem que obter resposta, é mais comum você ter um orquestrador que aciona ou ferramenta ou agente, tá? Quando você tem, por exemplo, um processo definido, onde você tá substituindo etapas do processo por agentes, aí você pode ter um um workflow sequencial, tá? O o Langflow é bom para desenhar isso, o Crew AI é bom para desenhar esse tipo de coisa, tá? Já o o Langchain dá para
          
          fazer também, mas eh isso depende do tipo de problema que você quer resolver, OK? Nada impede você ter o orquestrador, tá? mesmo que é para ser uma ação sequencial, você pode usar um orquestrador e aí explicar para ele como é que ele monta o planejamento de forma que ele execute sequencialmente aquela atividade. OK? Bom, então, ó, aqui a gente tem Long Chain, depois vocês dão uma olhadinha. Eh, temos aqui também o Lama Index, que é um cara muito legal, tá? Eh, principalmente se você for trabalhar com Hag, com CEI, onde
          
          você pode trabalhar com vários agentes colaborando, etc. Tá? O NN, para quem não sabe eh programação e quer usar uma ferramenta para fazer essas automações de fluxo, né, montar esses fluxos de de execução dos agentes, eh arrastando e soltando caixinha, tá? e o Long Flow, que também é uma interface visual que permite essa essa característica de ligação das caixinhas, né? Só que ele usa por baixo o Long Chain, tá bom? Qual usar, vocês vão ter que decidir em grupo, né, quando vocês forem fazer as atividades, qual que vai ser a
          
          melhor opção. Vocês tm gente que programa em Python no grupo? Vocês podem usar uma framework. Ah, não tenho. Então, usa um Langflow, um N8N ou outras eh ferramentas, tá? Qual que é o problema, por exemplo, de um Lang Flow, de um N8N? Quando você vai escalar isso aí, você precisa realmente aumentar o volume de processamento. Vamos supor que você criou uma aplicação, sei lá, vai que vai pegar uma nota fiscal e recuperar um monte de informação, tomar decisão e etc. Para uma nota, dá para você fazer
          
          usando uma ferramenta, um N8N, por exemplo, ou um Langflow. Mas se eu quiser ter centenas, milhares de notas, vários servidores rodando, aí vocês vão ter que entrar no moto pago dessas ferramentas e elas não costumam ser muito baratas, tá? Mesmo as ferramentinhas que elas liberam e o próprio Langchain também e as outras, algumas ferramentas são pagas. Ah, então eu quero usar a ferramenta de, sei lá, vai eh fazer web scraping. Ah, você vai ter que pagar a ferramenta. Então, essa é outra coisa interessante
          
          que você tem que pensar. Dependendo de como você vai fazer a solução, você tem custo da ferramenta que vai ser usado pela framework. o próprio custo da ferramenta, né, do do framework ou daquele ambiente que você tá usando para rodar tua solução, o custo da eh dos tokens que você tá mandando paraa tua LLM. E lembre-se, tá? Se eu tenho uma LLM que ela decide fazer algumas coisas e fica, vai na ferramenta, volta, vai volta, vai e volta, cada vez que ela faz um trabalho desse tipo, é token que tá indo, token que tá voltando e o negócio
          
          tá comendo lá, né? o o taxímetro ligado e você tá pagando por tudo isso. Então, dependendo de como você montar a arquitetura da tua solução, ela pode ficar linda, mas vai custar um caminhão de dinheiro. Isso também tem que ser avaliado. Pode, pode, sem problema nenhum. Eu acho que ele tem um agente para para WhatsApp, só que assim, de novo, né? Ah, vou usar o WhatsApp. Ah, para eu mandar uma mensagem no WhatsApp, eu tenho que ter uma conta comercial, tenho o custo envolvido disso. Se sou eu que faço a primeira interaração, se é a
          
          pessoa que me procura, você tem tarifações diferentes, você tem tarifação por cada mensagem enviada. Cara, é assim, ó. Você começou a usar profissionalmente, você pode ter certeza que alguém vai te enfiar a faca, tá? Ah, aqui quem é opence, quem é gratuito, é o seguinte, ó. Autogen eu não olhei, tá? Mas para idêntic é, Lin é lhama index é cria eu acho que não, tá? Ele tem lá um pedaço que é open, mas eu não fui atrás dos detalhes. N8N, você pode instalar ela localmente e aí rodando localmente você
          
          não paga, mas ela tem menos capacidades, que é a versão community que eles chamam, tá? E o Lang Flow ele usa o Lang Chain por baixo, mas ele tem lá a sessão de pricing. Então, se eu não me engano, se você for rodar em nuvem, você vai pagar, tá? Eu não vi a opção de rodar o Lang Flow localmente. OK, mas aí é só uma questão de você entrar e dar uma olhada. Ah, Léo, bom te ver. Pois é, é, é, é um problema, tá? principalmente se você for eh levar a solução com o conteúdo para fora, né, para rodar na nuvem. Você tem que montar
          
          uma camada de segurança, de criptografia e anonimização antes de jogar o dado para fora, tá? E assim, vamos supor o caso de um de um exame de imagem, né, um exame médico. Eh, em princípio, o exame em si, se você tomar o cuidado de tirar qualquer referência, inclusive, né, eh, anonimizar o o número lá do do prontuário do paciente, não chega a ser um problema, tá? Já vi até uma discussão dizendo que olha, eh, todo exame de imagem ele carrega características que são específicas de cada pessoa, mas
          
          assim, dá dá pra gente tratar isso, tá? E no mundo da medicina existem alguns protocolos de segurança que são específicos paraa área médica, tá? Eu não vou lembrar o nome agora, mas alguns anos atrás a gente tava vendo isso por causa das soluções da da data. Então assim, é possível, mas eh você vai ter que montar uma camada de de segurança muito boa ou, né, roda isso localmente dentro do ambiente ali, eh, local da instituição de saúde, só que aí você vai gastar uma grana boa com hardware para você ter um uma máquina
          
          lá, um HPC, tá? Ah, olha, eh, eu não eu não sei a a sigla VPS, eu não não conheço, tá? Mas você pode rodar o N8N local numa máquina normal, OK? O problema é assim, o N8N per si ele não é pesado. O que é pesado são as as LLMs que você vai acessar. Então você roda o N8N local acessando uma uma LLM na nuvem, beleza? Tá? é uma alternativa. Só que assim, lembra, o N8N local, ele tem muito menos capacidades que o N8N eh, que você roda em nuvem, que você vai pagar. Dependendo do do quanto você tá disposto a gastar, ele vai custar lá
          
          R e poucos reais por mês, tá? É uma solução para uma empresa pequena, dá para você fazer usando N8N que não vai não vai quebrar ninguém, tá, Pedro? É assim, ó. No fundo, no fundo, eh, para mim a melhor ferramenta é aquela que você sabe usar, ok? Então, se você se sentir confortável, eh, achar que a ferramenta gera o resultado que te interessa e você se sentir eh sentir proficiente naquela ferramenta, toca o barco. OK? O que você tem que ficar de olho sempre em relação à ferramenta é o seguinte: quem tá por trás da ferramenta
          
          é é uma ferramenta apaga ou é uma opence? Se é uma ferramenta open sece, ela tem sofrido atualização eh constante, porque às vezes você tem ferramenta que é muito legal, mas a comunidade abandonou. Aí você, cara, você investiu uma grana porque aquela ferramenta é muito legal, investiu tempo, investiu dinheiro para usar, só que a comunidade abandonou e você vai ficar com aquele mico na mão, tá? Eu já vi isso acontecer de monte ao longo dos anos, não só com com bibliotecas e etc, mas cara, com linguagem, com arquiteturas, enfim. A
          
          própria Microsoft fez isso há uns 10 anos atrás aí com algumas ferramentas para para criação web. Eles lançaram a ferramenta, deixaram dois anos no ar e descontinuaram. Eu vi empresa que investiu um caminão de dinheiro para usar a fer para usar aquela aquela ferramenta que a Microsoft criou, treinou a equipe, não sei o que lá, investiu e teve que jogar tudo no lixo e fazer de novo. Ah, que você pode usar a ferramenta que você quiser, tá? OK. Só lembra do seguinte, se eu tô fazendo, criando essa
          
          minha solução simplesmente para cumprir a agenda do curso, legal, use qualquer uma. Se eu tô usando a ferramenta ou a framework para construir um produto que eu pretendo vender, pense com carinho. Se eu tô construindo, né, a minha, o meu projeto para aprender a usar aquela framework ou aquela ferramenta, porque depois eu quero ir pro mercado e e demonstrar que eu sou um profissional valioso para as empresas e melhorar a minha empregabilidade, então escolha a framework ou a ferramenta que tá tendo
          
          melhor aceitação no mercado. De novo, essas são decisões de projeto. Ah, quando a gente pensar no projeto kid, pode ser eh qualquer uma, tá legal? Ah, se você Daqui a pouco eu vou dar vai passar uma atividade para vocês aí na atividade que eu vou passar para vocês, vocês vão ter que usar uma dessas aqui que estão aqui na listinha, OK? Mas eh para efeito do desenho do projeto de vocês, vocês podem usar qualquer uma, tá? Até tô curioso para ver o que que vai rolar. Alô. Ah, o arquivo está corrompido. Tá bom. Eu baixo ele, dou
          
          uma olhada. Qualquer coisa eu compacto novamente e subo, tá? Sem crise, drama. Beleza. Ah, autogen pentic ling train, Leng Flow. Então tá. Agora vamos falar do projeto de vocês. Legal. Então, que que vocês vão fazer? O desafio dois, eh, ao contrário, quem pegou o material que eu tinha colocado ontem, tá invertido, tá? Eu fui corrigindo algumas coisas. Então, a versão mais atual que tá lá no site é a que vale, tá? O desafio dois vai ser a primeira entrega que vocês como grupo vão fazer do seu projeto. Então, que que vocês vão ter
          
          que fazer? A proposta do que é o projeto que vocês querem desenvolver. Então, cada grupo tem que fazer um relatório. Esse relatório tem que ser em formato PDF. O nome do arquivo tem que seguir esse padrão que tá aqui. Então, nome do grupo_line propostad projeto. PDF. Legal. Ah, mas eu queria. Pode mandar do jeito que você quiser. Só que eu vou pôr um programa para buscar essa informação. Se o programa não encontrar nome do grupo, né, o nome do seu grupo underline propostadeprojeto. PDF, ele não vai
          
          entender o que é, vai falar que você não entregou e eu vou entender que vocês não entregaram, tá bom? a gente já passou por essa essa situação em outros carnavais, né? E deu um trabalho enorme pra gente conseguir arrumar tudo. Então vamos combinar aqui entre nós, tá? Sigam exatamente o que tá escrito aí, né? Não precisa do vinha, mas assim, põe o nome do grupo. Eh, que que esse relatório tem que conter? O nome do grupo, quem são os integrantes, o tema que vocês escolheram. Então você vai descrever o
          
          que que você pretende fazer, quem é o público alvo que você quer atender, OK? Ah, é a minha empresa, eh, são as as empresas de contabilidade, são as empresas de logística, não sei. Tá? Aí depende do que que vocês escolheram e como vocês vão fazer. Justificar por que você escolheu esse tema, por que ele é importante, o que que ele agrega de valor para aquele público alvo? Ah, se eu resolver esse problema aqui, eu vou conseguir economizar x horas por mês na minha empresa. Ah, esse é um problema recorrente nas empresas do ramo X YZ,
          
          porque o dado vem, blá blá blá blá blá blá, tá? me fazer a proposta preliminar de como é que vocês vão desenvolver o projeto. Então, cronogramazinho, não precisa ser nada sofisticado. Olha, a gente pretende no primeiro mês fazer isso, no segundo isso, no terceiro isso, a gente pretende chegar em tal resultado assim, assim, assado. Eh, e outros elementos adicionais que vocês tenham, né? tabela, gráfico, diagrama, hã, qualquer outro elemento que possa enriquecer esse teu, esse teu relatório. Só que a gente vai fazer um
          
          negócio diferente aqui. Vocês vão também imaginar que vocês têm que apresentar essa proposta de solução para de vocês para uma banca examinadora ou para um grupo de investidores. Então, vocês vão me fazer um pit deck. Nossa, Cels, nunca ouvi falar do que é um pitdeck. Bem-vindo. Aqui embaixo eu tenho um um tutorialzinho lá do Sebrai ensinando como é que se escreve Pitdeck, tá? Esse Pitdeck vai ser uma apresentação PowerPoint que teoricamente você faria, né? Quem já participou com startup nesse tipo de coisa, sabe como é que é o
          
          esquema. Você chega, você tem 5 minutos para passar seu recado. Legal. Então vai ser um um PowerPoint com 5, 10, 15 slides, sei lá quantos slides você pretende colocar, mas vocês vão gastar e é um conjunto de slides que você tem que conseguir eh explicar a sua ideia em 5 minutos. Esse arquivo, [Música] hum, Maurício, tanto faz, tá? Você colocar underline fica mais fácil para mim. Se não colocar eu vou colocar depois que eu fizer download do arquivo, não vai? Não faz diferença nenhuma. Eh, esse arquivo que vocês
          
          gerarem, ele tem que ser no formato PPTX. Nossa, mas eu tô usando a ferramenta do Google, Go Slides, eu não posso mandar o link pro Google Drive? Não, tem que anexar o arquivo no e-mail. Na outra na outra entrega que vocês me fizeram, teve gente que mandou o arquivo, só o link do Google Drive. Gente, a minha ferramenta que eu vou montar para isso, ela não tá esperando trabalhar com o link do Google Drive. Então, ah, então agora podemos escolher um tema. Qualquer um, não, qualquer um daqueles temas que eu apresentei para
          
          vocês, tá? OK. Lá a gente tinha vários temas, várias oportunidades de de criação de soluções, todas elas voltadas para tratamento de documentos fiscais. OK? Lógico que pode, Silvano. Aliás, ela provavelmente vai ser, tá? Porque à medida que a gente fori evoluindo, vocês vão aprender novas tecnologias, vão entender, né, que alguns desafios que vocês tinham imaginado que seriam simples não são simples. Vão entender que algumas coisas que eram complexas são resolvidas de forma muito simples e aí você vai ajustando seu projeto sem
          
          problema nenhum. Ah, olha, Natália, ainda eu não lembro se eu coloquei no cronograma para apresentar ou não. Tá aqui sim. Ah, as equipes vão apresentar, mas é o seguinte, não são todas, a gente tem mais de 300 equipes, não dá pro pessoal apresentar, tá? Então, eh, eu espero que pelo menos cinco a 10 equipes se voluntariem e aí as equipes vão apresentar as soluções dos seus projetos para que vocês vejam como é que o pessoal tá estruturando isso, tá? E aí quando a gente tiver naquela aula de apresentação, quem achar que não vale a
          
          pena assistir, não precisa assistir. Mas eu eu gosto muito de ver o que o pessoal tá fazendo, tá? OK. Sim, exatamente isso aí. É assim, né, eh, quando você tá montando, né, o teu pitdec, etc., Normalmente a gente faz uma pesquisa de mercado, olha para que que o tipo de solução, quem que é afetado por aquilo, etc. E aí você acaba criando alguns cenários para poder explicar ou você cria uma persona e explica o sofrimento dela, enfim. E aí alguns algumas tabelas, alguns gráficos são legais para para enriquecer a tua
          
          explicação, né? Às vezes você quer montar uma um diagrama de como é que o sistema vai funcionar, olha, ou a gente vai receber através de tal interação isso, vai fazer não sei o quê. vai disparar tal coisa, enfim, né? Aí fica à vontade. Não, ô Roberto, eh, esse é um caso que não é bem, a gente não vai bem eh trabalhar com Crisp, tá? Você até pode fazer lá aquela parte, na hora que você for descrever, né, a solução, fazer o entendimento do problema de negócios, explicar quais são as as os problemas que você encontrou e que
          
          que você pretende resolver, mas o restante do desenvolvimento do Crisp, que é a parte de dados, modelagem, etc., Não, você não vai conseguir enquadrar ele nesse, nesse momento no relatório, tá? Depois, à medida que as coisas forem caminhando, aí é provável que a gente consiga eh pegar as etapas do Crispe e e fazer a adequação delas. Mas nesse momento a gente tá muito embrionário ainda. Bom, outra coisa que eu fiz, eles vão observar que tem lá no no nosso site, na, aliás, na área de arquivos compartilhados, um cronograma versão
          
          dois, tá? A nossa próxima aula, onde vocês teriam que apresentar isso, seria no dia 5. Eu vou dar um uma oportunidade para vocês conseguirem se encontrar como grupo, trocar informação. Então, a gente não vai ter a aula do dia 5, tá? Falando de novo, ó. Dia 5 aula. Por que que não vai ter aula? Para dar tempo de vocês fazerem tudo que eu tô pedindo. Legal. Então, qual que é o limite para entregar isso? Dia 11/06 até às 23:59, OK? 12/06 às 0:01 não é 11/06. Nós também já passamos por pela experiência anterior, assim, eu dei lá
          
          uma colherzinha de chá, mas acabou, tá? Isso exatamente é esse mesmo, Thaago. Ali você tem as várias oportunidades lá de trabalhar. Você não precisa fazer uma solução mega complexa, pode ser alguma coisa simples, mas tem que tá dentro daquele conjunto, tá? Como é que vai ser essa entrega? O responsável pelo grupo vai pegar o o relatório em formato PDF, apresentação em formato PPTX, vai anexar num e-mail e mandar esse e-mail para aquele nosso famoso challenge@2.academ. O título do e-mail vai ser Agentes autônomos traç projeto
          
          traço entrega um. Legal. dica, o a pessoa que mandar o e-mail manda com cópia para si mesmo, porque se por algum motivo esse e-mail não chegar e você tiver que mostrar para mim que você mandou o e-mail, eu vou querer verar a cópia que você mandou para si mesmo. Ah, eu quero dar ciência para os meus colegas. Então, manda esse e-mail com cópia para todo mundo que faz parte do grupo, OK? Dia 12. a gente vai ter a apresentação dessas soluções, tá? Dos pitzinhos. Legal. Então, eu gostaria que vários grupos se eh voluntariassem para
          
          apresentar as soluções que eles querem encontrar. Lembre que isso aqui vai tá disponível para todo mundo. Eh, a solução que vocês estão propondo vai tá aberta para todos. Aqui a gente tá num ambiente de aprendizagem. Então se você for trabalhar com alguma coisa que vai ser segredo industrial, que tem propriedade intelectual envolvida, não apresente, OK? Mas também a gente vai ter que depois eh ver como é que nós vamos fazer com isso, mas é outra história, tá? Então espero que vários se manifestem. Por exemplo, Aila, pode ser,
          
          né? Ah, a minha contabilidade recebe muito documento fiscal e eu perco muito tempo fazendo a a tentando recuperar das notas fiscais qual o imposto que tá lá eh destacado na nota e fazer o cálculo para ver se aquele imposto tá certo e fazer o lançamento contábil da entrada da nota fiscal no estoque e dos impostos, né, na nas contas de receitas e despesas, por exemplo. Ah, mas eu não entendo nada disso. Beleza, você pode mandar a pergunta lá pro naquele nosso formulário de dúvidas ou vê se tem alguém, né, nos
          
          grupos aí que é especializado nessa parte contábil e pedir pra pessoa integrar o grupo de vocês, tá? Não. O que acontece, Thago, é o seguinte. Eu já posterguei justamente porque tem uma segunda atividade que eu vou descrever daqui a pouquinho. Então assim, isso era para ter sido entregue no dia 5 e no dia 12. Eu joguei uma semana paraa frente, fui lá no nosso cronograma, tirei um dia, né, uma semana que a gente tinha lá no final do cronograma, certo? e aloquei ela aqui pro começo para dar tempo de vocês
          
          cumprirem as duas atividades, a atividade do dia 2 e a atividade do dia 18. Ambas são eliminatórias. Sim, senhor. Senor Rodrigo, se não entregar, o grupo todo é eliminado. Depende do que você chama de viabilidade financeira, tá, Jeferson? Bom, então, ó, estamos combinados, tá? Entrega por e-mail para challenge@2.academ. Se mandar para Celso@2.academy, eu vou apagar o e-mail e vou fingir que eu não recebi. Legal. Se mandar para SAC@22.academy, a gente vai apagar o e-mail e fingir que não recebeu. Tem que
          
          ser para challenge, porque o programa que vai procurar o que vocês enviaram, ele vai buscar nessa conta de e-mail. Legal. Se mandarem para outra, sinto muito, vocês cometeram um erro fatal. Eh, isso aqui também é importante, pode, depende como você vai criar a solução, tá, Sérgio? O colega perguntou, mas eu vou reforçar. Essa é uma atividade que deve ser feita em grupo. Se não entregarem, a responsabilidade é do grupo e, portanto, o grupo será eliminado. E se vocês depois vierem para mim falar: "Não, mas
          
          o grupo foi eliminado, mas o o nosso responsável pisou na bola, não sei o quê, tararal". Sinto muito. Então, garantam, né, que as coisas vão ser enviadas dentro do prazo estabelecido. E eu não tô pedindo, gente, excelência. Vocês podem fazer alguma coisa mais simples, mas não deixem de mandar. Quem do grupo não participar da atividade, demite e esse cara vai ser eliminado do curso porque ele não faz parte de nenhum grupo. Simples assim. OK. Beleza, fechamos então a questão do desafio dois. Então vamos
          
          lá. Agora uma atividade para vocês exercitarem tudo isso que a gente discutiu, tá? Então o que que vocês vão fazer? Vocês vão criar um ou mais agentes que torne possível pro usuário fazer perguntas sobre os arquivos CSV que a gente mandou para vocês aqui, tá? Esses arquivos, na verdade, são 100 notas que eu peguei aleatoriamente lá na naquele arquivo que eu que eu baixei da receita da receita, não, do Tribunal de Contas da União. E é os itens que compõem cada uma daquelas notas, tá? Mas eu quero que você possa
          
          perguntar assim, eh, qual item teve o maior valor? Ah, existe algum item que ou me mostre os top 10 itens que t maior volume de compras, quem é o o fornecedor que recebeu mais dinheiro? Qual a cidade que tem maior volume de compras? E assim por diante. Legal. Então você vai ter que ter uma interfaceinha que pode ser simples, linha de texto, assim, aquela coisa bem rústica, tá? onde o usuário vai informar a pergunta ou a agente vai obter a resposta, tá? Que que se a gente vai ter que fazer? Descompactar o
          
          arquivo, selecionar o arquivo em função da da pergunta, se é de item de nota ou se é da própria nota, carregar esses dados para memória, fazer as queres e gerar a resposta pro usuário. OK? Ah, sim, com certeza, com certeza. Tá. Esse, esse inclusive seria um negócio bem interessante, né? Ah, sim, sem problema nenhum, fique à vontade, tá? OK. Pois é, ô, ô, Carlos, seria, mas assim, é mais uma ferramenta que o pessoal ia ter que aprender, né? Eu até gosto muito da da ideia de ter, por exemplo, um business model campus para
          
          você testar modelo de negócio, né? Mas eh eu não sei se todo mundo aqui tá acostumado com esse tipo de de ferramenta e eu acho que sairia um pouquinho do foco do curso que é a construção de agente, tá? Mas a ideia é boa. Você quiser usar ou ou convidar outros colegas para para poder estudar o business model canvas, é é uma ferramenta fantástica, tá gente? Existem ferramentas para modelagem de problemas de negócio que são muito boas. O Business Model Canvas é uma delas e o Cardos tem razão em em sugerir, tá? Mas
          
          assim, estaria saindo um pouco fora do nosso escopo, só por isso que eu não sugeri, tá? Ah, que recurso que vocês têm, então, para poder fazer? Você tem o arquivo CSV que eu joguei lá no site, ele tá lá no site que aponta pro driver compartilhado ou se quiser ir lá no drive direto, tá? Eh, o colega de vocês falou que teve problema lá na hora que descompactou. Eu vou baixar o o arquivo, vou ver se ele tá com problema. Qualquer coisa eu subo uma versão nova dele. Eh, mas vocês podem ter certeza que o
          
          arquivo vai est direitinho, tá? Quais tecnologias vocês vão usar? Vocês têm que usar pelo menos uma das ferramentas ou frameworks que a gente sugeriu aqui, né, que eu mostrei o o autogen, pidentic, lang chain, lama index, crew ai n flow. Ah, posso usar duas, posso usar três, posso experimentar todas, fique à vontade, tá? Outra coisa, esse trabalho deve ser desenvolvido em grupo. Legal. Se a gente tá falando que vai ser feito em grupo, vocês vão ter que se dividir. Uma parte, por exemplo, vai ser quem vai planejar o
          
          agente, a outra vai pesquisar quais ferramentas, a outra parte vai escrever o código, enfim, vocês têm que trabalhar tudo isso. Eh, ah, eu tô escrevendo código Python, não sei o quê. deposita lá no GitHub que vocês criaram do grupo. Isso é uma evidência que vocês estão fazendo e é um lugar onde todos podem colaborar, tá? Ah, eu tô usando uma ferramenta tipo NN e eu tô no modo lá single, só consigo eu mesmo fazer, mas você pode se alimentar das dos recursos, das opiniões que cada um fez. Você pode ter duas ou
          
          mais pessoas experimentando ferramentas diferentes para ver qual que gera o melhor resultado. Enfim, pessoal, usem a sua criatividade e eu sei que vocês têm muito de novo, como é que vai ser a entrega? Um relatório PDF falando qual framework você escolheu ou qual ferramenta, tá? como é que você estruturou a sua solução? Colocar lá pelo menos quatro perguntas com as respectivas respostas. Se conseguir ainda mostrar como é que foi o raciocínio da ferramenta, como é que ela se organizou para responder, melhor
          
          ainda, enriquece o seu relatório. O link paraa pastinha lá do seu GID Hub ou eh algum link pra gente poder acessar seu agente na nuvem, tá? Provavelmente vocês vão ter que usar a chave de software para para definir lá qual Llsão usando. Tem algumas que são free, você consegue a chave na boa, mas assim, lembrem-se de ocultar as chaves, tá? Eh, se vocês forem adquirir alguma coisa aí da, sei lá, da Open Ai, Brock, enfim, seja lá quem for, né? Eh, cara, coloca dó, sabe? Gasta lá R$ 5, R$ 10, se for
          
          coisa. Faz uma uma vaquinha pra turma toda aí do grupo a R$ 1 cada um e põe lá R$ 10. Tá? Agora, o que que é importante? Eu não quero que você abra LLM e vá, sabe? Faça o upload do arquivo e vai fazendo pergunta. Isso eu sei fazer. Qualquer um pode fazer. Não é isso. Eu quero que o agente faça isso. Legal. E vocês têm que mostrar para mim que o agente de fato fez. A entrega vai ser por e-mail. De novo. O responsável envia pro challenge@2academy, manda uma cópia para si mesmo para ter o protocolo do envio,
          
          tá? E o e o arquivo PDF anexado. Título do e-mail: agentes autônomos, análise de CSV. Se quiser mandar pros demais colegas para falar para eles, tô mandando protocolar tudo isso, joia. Qual que é o limite de entrega? 18/06. Vocês vão ter três semanas para resolver isso. Esse é um problema simples, legal. Em termos de construção de agente. O pessoal que tá acostumado a trabalhar com isso e principalmente com essas ferramentas no code, resolve isso em alguns minutos, talvez em pouco menos de uma du horas.
          
          Então, três semanas, tá galera? Pelo amor de Deus. De novo, o limite é 18/06. 18/06 2359. 19/06 a meianoite 1 minuto, não é 18/06. E de novo, essa é uma atividade eliminatória. Se não tiver entrega, o grupo roda. Não, o banco de dados não é sintético, tá, Léo? Eh, são dois arquivos texto, tá? separado por vírgula, já tá disponível lá no site. Eu só vou testar porque um um dos colegas de vocês disse que baixou o arquivo e e parece que ele tá corrompido. Eu quero ter certeza que ele esteja legal. Eh, e
          
          esses dados eu obtive no portal da transparência do governo federal. Se você entrar lá no Tribunal de Contas da União, tem eh as notas fiscais, eu acho que de últimos três ou 5 anos, de todas as notas fiscais de que o que o Tribunal de Contas da União, eu não sei se são os que ele avaliou ou se são as notas fiscais que eh alguns órgãos lá que estão sob a a análise do TCU enviado, tá? Mas assim, tem um caminhão de nota fiscal lá, um monte mesmo. E é muito legal porque assim, são dados reais, tá? São compras
          
          efetivamente realizadas por órgãos públicos. É isso aí, Thaago. A atividade dois, né? O desafio dois, que é a parte do do projeto, vocês vão fazer até o dia 12. Então vocês têm duas semanas para fazer isso e essa daqui vocês têm que entregar até o dia 18. Vocês têm três semanas para fazer isso. Beleza? Hum. Não tem nenhuma obrigatoriedade em particular, tá, Cléber? Você pode usar da forma como você achar melhor. Você pode, por exemplo, ter um agente que pega o teu arquivo CSV ou eh sei lá, escreve um código que gera um código
          
          Python e carrega esses esses arquivos num num Pandas. E aí você faz a análise a partir do resultado do pandas. Você pode eh o teu agente pode, por exemplo, pegar esses dados, gravar num num banquinho de dados. SK e aí você ter um um uma outra ferramenta de querer de banco de dados, né? Ou você pode embedar mesmo, tá? E jogar lá no contexto. Aí é uma questão de como é que você pretende criar. Ahã. Vai lá pro N8N ou Lang Chain, tá? Grazelo? Lang chain não, Lang Flow. Essas são são visuais. Ahã. Dia 11. Pera aí, deixa eu
          
          conferir. É dia 11, verdade, Fabiano. Dia 11 é a entrega, dia 12 é a apresentação. Certo? Muito obrigado. Tá, eu acabei falando errado, né? É dia 11 a entrega, dia 12 a apresentação e essa e esse outro agente é no dia 18 a entrega, tá? No dia 19 nós não vamos fazer apresentação. Sim, você pode, tá, Anderson? Só toma cuidado para não deixar a coisa ficar em cima da hora, tá? Então, já comecem a se movimentar, a conversar entre vocês, porque se os outros integrantes não se manifestar, cara, sai fora.
          
          Beleza? Perguntas. Vocês já se divertiram bastante com bastante pergunta. E aí eu espero que vocês tenham bastante divertimento, tá? Dia 11, data de MIT, mas pode ser entregantes. Claro, Joel. Aliás, eh, eu já vi aluno dançar feio, assim, perdeu o curso porque deixou para mandar em cima da hora e no dia que ele foi mandar, a internet dele não tava no ar e aí o cara perdeu o prazo, tá? Você pode só exportar o workflow, mas se você quiser deixar o link pra gente testar, é mais legal, né? que aí eu olho lá coisa funcionando, tá
          
          bom? Beleza, pessoal. Agradeço a a oportunidade de estar aqui novamente conversando com vocês. Eh, eu tenho observado lá nas nas estatísticas das lives que a gente tem tido um uma um acesso massivo nos vídeos, tá? Então, parabéns todos vocês. Também tem observado lá nos grupos que agora que a gente fez essa divisão, né, tem lá a área onde o pessoal tem batido papo, conversado algumas coisas, mas o respeito tem sido mantido entre todos vocês. Vocês estão cumprindo aquelas regras de de convivência. Eu eu fico
          
          muito feliz de ver que a gente alcançou um nível de maturidade muito bom ali nos nossos diálogos, tá? Só para vocês terem uma ideia, ontem eu tive que eliminar 12 alunos do de um outro curso que nós estamos fazendo porque eles violaram a regra do grupo, tá? E aí eh eu fiquei muito chateado e e eu tô muito feliz de ver que isso não tá acontecendo aqui. Então, por favor, continuem assim, tá? Lembrem-se também o seguinte, aqui no nos grupos tem um monte de ex-aluno do I2A2, tá? Eles podem te dar te dar dicas
          
          eh de como é que é o dia a dia da de tudo isso, OK? Então nós nos vemos de novo no dia 12, tá? E dia 12 vai ser a apresentação do material produzido por alguns dos grupos. Legal? Obrigado a todos vocês e os espero lá no dia 12, dia 5. Se alguém tiver alguma dúvida, quiser fazer um um call rápido, alguma coisa assim, de repente a gente até pode fazer, mas não é um uma aula normal, tá? Não, não pretendo eh ter a aula, que é justamente para que vocês tenham oportunidade de eh se concentrarem, quem não sabe Python
          
          aprend Python, construir o projeto de vocês e trabalhar para que a entrega do dia 18 seja uma entrega fantástica. Os vejo em breve. [Música] [Música] เฮ [Música] [Música] [Música] [Música]
          